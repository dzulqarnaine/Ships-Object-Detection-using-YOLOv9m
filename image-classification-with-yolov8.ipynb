{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQuhhBbOPsY7",
        "outputId": "4f1797ed-aa25-45ba-a214-1e80c18b4138"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.16.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.12.14)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.59-py3-none-any.whl.metadata (35 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.13-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.12.14)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.59-py3-none-any.whl (906 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m906.8/906.8 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.13-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.59 ultralytics-thop-2.0.13\n",
            "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "/content\n",
            "/content/datasets\n"
          ]
        }
      ],
      "source": [
        "!pip install gdown\n",
        "!pip install ultralytics\n",
        "\n",
        "import csv\n",
        "from ultralytics import YOLO\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "import gdown\n",
        "import zipfile\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import matplotlib.image as mpimg\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import shutil\n",
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(HOME)\n",
        "\n",
        "!mkdir {HOME}/datasets\n",
        "%cd {HOME}/datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# ID file dari tautan\n",
        "file_id = \"1QDCT7w0TaG7hTu33Kcm-wBxGrsV9UEz9\"\n",
        "file_name = \"ships-aerial-images\"  # Nama file untuk menyimpan unduhan\n",
        "\n",
        "\n",
        "try:\n",
        "    print(f\"Mengunduh file dengan ID {file_id}...\")\n",
        "    downloaded = drive.CreateFile({'id': file_id})\n",
        "    downloaded.GetContentFile(file_name)\n",
        "    print(f\"File berhasil diunduh sebagai {file_name}!\")\n",
        "except Exception as e:\n",
        "    print(f\"Terjadi error saat mengunduh file: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMdazokdQL3G",
        "outputId": "0489b314-8b1f-435e-8fd4-09b7310edb07"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:pydrive is deprecated and no longer maintained. We recommend that you migrate your projects to pydrive2, the maintained fork of pydrive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mengunduh file dengan ID 1QDCT7w0TaG7hTu33Kcm-wBxGrsV9UEz9...\n",
            "File berhasil diunduh sebagai ships-aerial-images!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/datasets/ships-aerial-images -d /content/data"
      ],
      "metadata": {
        "id": "ZzalSgbJQSAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "\n",
        "def count_items_in_directory(directory):\n",
        "    try:\n",
        "        return sum(len(files) for _, _, files in os.walk(directory))\n",
        "    except FileNotFoundError:\n",
        "        return 0\n",
        "\n",
        "def count_items(base_path):\n",
        "    categories = ['train', 'valid', 'test']\n",
        "    classes = [\"images\", 'labels']\n",
        "    total_images = 0\n",
        "\n",
        "    for category in categories:\n",
        "        print(f\"--- {category.capitalize()} Data ---\")\n",
        "        category_path = os.path.join(base_path, category)\n",
        "        for class_name in classes:\n",
        "            class_path = os.path.join(category_path, class_name)\n",
        "            num_items = count_items_in_directory(class_path)\n",
        "            total_images += num_items\n",
        "            if num_items > 0:\n",
        "                print(f\"{class_name.capitalize()}: {num_items} images\")\n",
        "            else:\n",
        "                print(f\"{class_name.capitalize()}: Directory does not exist or is empty\")\n",
        "\n",
        "    print(f\"\\nTotal Images: {total_images} images\")\n",
        "\n",
        "# Define base path\n",
        "base_path = '/content/data/ships-aerial-images'\n",
        "count_items(base_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvGEc9gVRgRB",
        "outputId": "4628ac06-6713-4d39-f4d2-f7bc142e765b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Train Data ---\n",
            "Images: 9697 images\n",
            "Labels: 9697 images\n",
            "--- Valid Data ---\n",
            "Images: 2165 images\n",
            "Labels: 2165 images\n",
            "--- Test Data ---\n",
            "Images: 1573 images\n",
            "Labels: 1573 images\n",
            "\n",
            "Total Images: 26870 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "def check_images_in_directory(directory):\n",
        "    invalid_images = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            # Pastikan hanya file dengan ekstensi gambar yang diproses\n",
        "            if file.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp', '.tiff')):\n",
        "                try:\n",
        "                    img_path = os.path.join(root, file)\n",
        "                    img = Image.open(img_path)\n",
        "                    img.verify()  # Memverifikasi gambar (hanya memeriksa header)\n",
        "                except (IOError, Image.UnidentifiedImageError) as e:\n",
        "                    print(f\"File tidak valid ditemukan: {img_path}, Error: {e}\")\n",
        "                    invalid_images.append(img_path)\n",
        "                except Exception as e:\n",
        "                    print(f\"Unexpected error for {img_path}: {e}\")\n",
        "                    invalid_images.append(img_path)\n",
        "    return invalid_images\n",
        "\n",
        "# Periksa direktori gambar saja, abaikan folder \"labels\"\n",
        "train_dir = \"/content/data/ships-aerial-images/train/images\"\n",
        "validation_dir = \"/content/data/ships-aerial-images/valid/images\"\n",
        "\n",
        "invalid_train_images = check_images_in_directory(train_dir)\n",
        "invalid_validation_images = check_images_in_directory(validation_dir)\n",
        "\n",
        "print(\"Invalid train images:\", invalid_train_images)\n",
        "print(\"Invalid validation images:\", invalid_validation_images)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWsGhK34VGaG",
        "outputId": "0eef8e0c-7465-4277-8507-de8e3dc93b2c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Invalid train images: []\n",
            "Invalid validation images: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "def check_images_in_directory(directory):\n",
        "    invalid_images = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            try:\n",
        "                img_path = os.path.join(root, file)\n",
        "                img = Image.open(img_path)\n",
        "                img.verify()\n",
        "            except (IOError, Image.UnidentifiedImageError) as e:\n",
        "                invalid_images.append((img_path, str(e)))\n",
        "    return invalid_images\n",
        "\n",
        "# memeriksa semua dataset\n",
        "invalid_train_images = check_images_in_directory(\"/content/data/ships-aerial-images/train\")\n",
        "invalid_validation_images = check_images_in_directory(\"/content/data/ships-aerial-images/validation\")\n",
        "\n",
        "if invalid_train_images:\n",
        "    print(\"Invalid images found in train dataset:\")\n",
        "    for img_path, error in invalid_train_images:\n",
        "        print(f\"File tidak valid ditemukan: {img_path}, Error: {error}\")\n",
        "\n",
        "if invalid_validation_images:\n",
        "    print(\"Invalid images found in validation dataset:\")\n",
        "    for img_path, error in invalid_validation_images:\n",
        "        print(f\"File tidak valid ditemukan: {img_path}, Error: {error}\")"
      ],
      "metadata": {
        "id": "nhAHWHxOTyiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "import ultralytics\n",
        "ultralytics.checks()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozw1DJr0XnBa",
        "outputId": "f7a1a262-64e3-4336-c9c8-0b6fa8816fdf"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.59 ðŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 33.3/112.6 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "from IPython.display import display, Image\n",
        "\n",
        "os.environ['WANDB_MODE'] = 'disabled'"
      ],
      "metadata": {
        "id": "UNIb63qQXq-g"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo task=detect mode=train model=yolov9m.pt data=\"/content/data/ships-aerial-images/data.yaml\" epochs=20 imgsz=256 batch=32 device=0 workers=8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKu-QcicYO5O",
        "outputId": "049f11cb-9ed5-4c4e-f9ca-c444c42e99a0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov9m.pt to 'yolov9m.pt'...\n",
            "100% 39.1M/39.1M [00:00<00:00, 123MB/s]\n",
            "Ultralytics 8.3.59 ðŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov9m.pt, data=/content/data/ships-aerial-images/data.yaml, epochs=20, time=None, patience=100, batch=32, imgsz=256, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n",
            "100% 755k/755k [00:00<00:00, 19.2MB/s]\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1    171648  ultralytics.nn.modules.block.RepNCSPELAN4    [64, 128, 128, 64, 1]         \n",
            "  3                  -1  1    276960  ultralytics.nn.modules.block.AConv           [128, 240]                    \n",
            "  4                  -1  1    629520  ultralytics.nn.modules.block.RepNCSPELAN4    [240, 240, 240, 120, 1]       \n",
            "  5                  -1  1    778320  ultralytics.nn.modules.block.AConv           [240, 360]                    \n",
            "  6                  -1  1   1414080  ultralytics.nn.modules.block.RepNCSPELAN4    [360, 360, 360, 180, 1]       \n",
            "  7                  -1  1   1556160  ultralytics.nn.modules.block.AConv           [360, 480]                    \n",
            "  8                  -1  1   2511840  ultralytics.nn.modules.block.RepNCSPELAN4    [480, 480, 480, 240, 1]       \n",
            "  9                  -1  1    577440  ultralytics.nn.modules.block.SPPELAN         [480, 480, 240]               \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1   1586880  ultralytics.nn.modules.block.RepNCSPELAN4    [840, 360, 360, 180, 1]       \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    715920  ultralytics.nn.modules.block.RepNCSPELAN4    [600, 240, 240, 120, 1]       \n",
            " 16                  -1  1    397808  ultralytics.nn.modules.block.AConv           [240, 184]                    \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1   1480320  ultralytics.nn.modules.block.RepNCSPELAN4    [544, 360, 360, 180, 1]       \n",
            " 19                  -1  1    778080  ultralytics.nn.modules.block.AConv           [360, 240]                    \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1   2627040  ultralytics.nn.modules.block.RepNCSPELAN4    [720, 480, 480, 240, 1]       \n",
            " 22        [15, 18, 21]  1   4637539  ultralytics.nn.modules.head.Detect           [1, [240, 360, 480]]          \n",
            "YOLOv9m summary: 603 layers, 20,159,043 parameters, 20,159,027 gradients, 77.5 GFLOPs\n",
            "\n",
            "Transferred 901/907 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n",
            "100% 5.35M/5.35M [00:00<00:00, 84.8MB/s]\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data/ships-aerial-images/train/labels... 9697 images, 351 backgrounds, 2 corrupt: 100% 9697/9697 [00:04<00:00, 1957.14it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/data/ships-aerial-images/train/images/1__20180714_180427_1029__-118-20071740708637_33-73029905538088_png.rf.330efa80ecbf49d6ceac7071288d64b4.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0249]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/data/ships-aerial-images/train/images/1__20180714_180427_1029__-118-21100741654266_33-732092454738826_png.rf.7243f2b58b505e51950850f4b26081ba.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0079]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data/ships-aerial-images/train/labels.cache\n",
            "WARNING âš ï¸ Box and segment counts should be equal, but got len(segments) = 709, len(boxes) = 19454. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.0 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data/ships-aerial-images/valid/labels... 2165 images, 68 backgrounds, 0 corrupt: 100% 2165/2165 [00:01<00:00, 1408.74it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/data/ships-aerial-images/valid/labels.cache\n",
            "WARNING âš ï¸ Box and segment counts should be equal, but got len(segments) = 172, len(boxes) = 3720. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 149 weight(decay=0.0), 156 weight(decay=0.0005), 155 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
            "Image sizes 256 train, 256 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       1/20      3.21G       1.81      1.769      1.544         90        256: 100% 303/303 [01:43<00:00,  2.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 34/34 [00:14<00:00,  2.36it/s]\n",
            "                   all       2165       3720     0.0542      0.179     0.0171    0.00563\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       2/20      3.15G      1.857      1.707      1.583         82        256: 100% 303/303 [01:35<00:00,  3.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 34/34 [00:13<00:00,  2.58it/s]\n",
            "                   all       2165       3720      0.436      0.291      0.242     0.0967\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       3/20      3.08G      1.847      1.811      1.713         79        256:   0% 1/303 [00:00<04:06,  1.23it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/yolo\", line 8, in <module>\n",
            "    sys.exit(entrypoint())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/cfg/__init__.py\", line 973, in entrypoint\n",
            "    getattr(model, mode)(**overrides)  # default args from model\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\", line 806, in train\n",
            "    self.trainer.train()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\", line 207, in train\n",
            "    self._do_train(world_size)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\", line 388, in _do_train\n",
            "    self.scaler.scale(self.loss).backward()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\", line 581, in backward\n",
            "    torch.autograd.backward(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
            "    _engine_run_backward(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\", line 825, in _engine_run_backward\n",
            "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wYGRsJTdY4R4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}